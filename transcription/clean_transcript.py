"""
Clean transcript using Azure OpenAI to fix Whisper V3 transcription errors.
"""

import json
import os
import sys
from pathlib import Path

from dotenv import load_dotenv
from openai import AzureOpenAI


TERMS_FILE = Path(__file__).parent / "terms.json"


def load_config():
    """Load Azure OpenAI configuration from environment variables."""
    load_dotenv()
    
    api_key = os.getenv("AZURE_OPENAI_API_KEY")
    endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
    deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
    api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2024-08-01-preview")
    
    if not all([api_key, endpoint, deployment_name]):
        raise ValueError(
            "Missing required environment variables. "
            "Please set AZURE_OPENAI_API_KEY, AZURE_OPENAI_ENDPOINT, "
            "and AZURE_OPENAI_DEPLOYMENT_NAME in your .env file."
        )
    
    return {
        "api_key": api_key,
        "endpoint": endpoint,
        "deployment_name": deployment_name,
        "api_version": api_version,
    }


def create_client(config: dict) -> AzureOpenAI:
    """Initialize the Azure OpenAI client."""
    return AzureOpenAI(
        api_key=config["api_key"],
        api_version=config["api_version"],
        azure_endpoint=config["endpoint"],
    )


def load_term_context() -> str:
    """Load terminology context from terms.json if available."""
    if not TERMS_FILE.exists():
        return "No specialized terminology provided."
    
    try:
        data = json.loads(TERMS_FILE.read_text(encoding="utf-8"))
    except (json.JSONDecodeError, OSError):
        return "No specialized terminology provided."
    
    context_desc = data.get("context_description", "")
    terms = data.get("terms", {})
    
    if not terms:
        return "No specialized terminology provided."
    
    lines = []
    if context_desc:
        lines.append(f"Context Description: {context_desc}")
    
    lines.append("Terminology Reference:")
    for category, items in terms.items():
        category_display = category.replace("_", " ")
        items_str = ", ".join(items) if isinstance(items, list) else str(items)
        lines.append(f"- {category_display}: {items_str}")
    
    return "\n".join(lines)


def load_json_context() -> str:
    """Load the raw JSON context for embedding in the prompt."""
    if not TERMS_FILE.exists():
        return "{}"
    
    try:
        return TERMS_FILE.read_text(encoding="utf-8")
    except OSError:
        return "{}"


def parse_srt_entries(content: str) -> list:
    """
    Parse SRT content into a list of entries.
    Each entry is a dict with 'index', 'timestamp', 'text', and 'raw' (original block).
    """
    entries = []
    lines = content.strip().split('\n')
    
    i = 0
    while i < len(lines):
        if lines[i].strip().isdigit():
            entry_lines = []
            while i < len(lines) and lines[i].strip():
                entry_lines.append(lines[i])
                i += 1
            entry_lines.append('')
            entries.append('\n'.join(entry_lines))
        else:
            i += 1
    
    return entries


def split_srt_into_chunks(content: str, batch_size: int = 15, overlap: int = 2) -> list:
    """
    Split SRT content into chunks of batch_size subtitle entries with overlap.
    
    Args:
        content: Full SRT content
        batch_size: Number of entries per chunk (10-20 recommended)
        overlap: Number of previous entries to include as read-only context
    
    Returns:
        List of tuples: (context_entries, main_entries) where context is read-only
    """
    entries = parse_srt_entries(content)
    
    if len(entries) <= batch_size:
        return [([], entries)]  # No context needed for small files
    
    chunks = []
    i = 0
    while i < len(entries):
        # Get context from previous entries (read-only)
        context_start = max(0, i - overlap)
        context_entries = entries[context_start:i] if i > 0 else []
        
        # Get main entries for this batch
        main_entries = entries[i:i + batch_size]
        
        chunks.append((context_entries, main_entries))
        i += batch_size
    
    return chunks


def clean_transcript(client: AzureOpenAI, deployment_name: str, content: str, json_context: str) -> str:
    """
    Send transcript to Azure OpenAI for cleaning.
    Processes entire SRT at once, or in chunks of 50 entries for very long files.
    """
    system_prompt = f"""You are an expert Cantonese ASR (Automatic Speech Recognition) Post-Editing Specialist. Your task is to correct errors in an SRT subtitle file generated by an AI model (like Whisper) from an audio source with high background noise or overlapping speech.

Your primary goal is to resolve "Logic Hallucinations"—instances where the ASR transcribed a word that is phonetically similar to the correct word but contextually nonsensical.

### CORE INSTRUCTIONS:
1. **Phonetic Restoration:** If a phrase is grammatically valid but logically absurd (e.g., "食咗飯" vs "殺咗犯"), analyze the phonetic pronunciation (Jyutping). If the nonsensical word shares a similar pronunciation with a word that fits the context, correct it.
2. **Contextual Continuity:** Look at the lines immediately before and after the current line. Ensure the dialogue flows logically.
   - *Example:* If the previous line is about "guns" and "shooting," and the current line mentions "windows" (窗 - coeng1) but the verb implies a weapon, correct "window" to "gun" (槍 - coeng1).
3. **Idiom Correction:** Watch for fractured idioms. ASR often breaks 4-character idioms into separate, unrelated words.
   - *Example:* Correct "梅花間 粥" (Plum flower porridge) to "梅花間竹" (Intermittent/Alternating) if the context implies a pattern.
4. **Preserve Structure:** You must output a valid SRT format. Do not change timestamps. Do not merge lines unless it is clearly a broken sentence.
5. **Dialect Handling:** Maintain Hong Kong Cantonese colloquialisms (e.g., "抵死", "古惑"). Do not convert them to Standard Written Chinese (SWC) unless the input was already SWC.

### FEW-SHOT EXAMPLES:

**Input (Error):**
00:01:16,000 --> 00:01:18,000
呢支槍全名叫做古樂的窗。

**Reasoning:**
"古樂" (Ancient music) sounds like "古惑" (Tricky). "窗" (Window) sounds like "槍" (Gun). The context is about a weapon.

**Output (Correction):**
00:01:16,000 --> 00:01:18,000
呢支槍全名叫做古惑的槍。

---

**Input (Error):**
00:01:20,000 --> 00:01:22,000
向後射完再向前梅花間粥咁嚟㗎嘛。

**Reasoning:**
"粥" (Porridge/Juk1) is a homophone for "竹" (Bamboo/Zuk1). "梅花間竹" is the correct idiom for an alternating pattern.

**Output (Correction):**
00:01:20,000 --> 00:01:22,000
向後射完再向前梅花間竹咁嚟㗎嘛。

---

**Input (Error):**
00:01:44,000 --> 00:01:46,000
即係渡後槍一開就渡後射㗎

**Reasoning:**
"渡後" sounds like "到後" (backwards). When talking about a gun that shoots backwards, "到後射" makes sense.

**Output (Correction):**
00:01:44,000 --> 00:01:46,000
即係到後槍一開就到後射㗎

---

**Input (Error):**
00:01:47,000 --> 00:01:49,000
越係咁Feel, 等等我

**Reasoning:**
"越係咁Feel" is nonsensical. In context of someone bleeding from a gunshot, "血係咁飙" (blood is spurting) fits perfectly.

**Output (Correction):**
00:01:47,000 --> 00:01:49,000
血係咁飙, 等等我

---

**Input (Error):**
00:01:23,000 --> 00:01:24,000
重大雨

**Reasoning:**
"重大雨" (heavy rain) doesn't fit the context. This is likely "仲打魚" or similar - but if context is about guns, it may be a short exclamation that should be kept minimal or merged.

**Output (Correction):**
00:01:23,000 --> 00:01:24,000
仲打乜

### FINAL CONSTRAINT:
If a line is already correct and logical, output it exactly as is. Do not paraphrase."""

    chunks = split_srt_into_chunks(content, batch_size=15, overlap=2)
    
    if len(chunks) == 1:
        print(f"Processing entire file ({len(content)} characters)...")
    else:
        print(f"Processing {len(chunks)} chunks (batch_size=15, overlap=2)...")
    
    cleaned_chunks = []
    for i, (context_entries, main_entries) in enumerate(chunks):
        if len(chunks) > 1:
            print(f"  Processing chunk {i + 1}/{len(chunks)} ({len(main_entries)} entries)...")
        
        # Build the user message with context
        if context_entries:
            context_block = '\n'.join(context_entries)
            main_block = '\n'.join(main_entries)
            user_content = f"""### PREVIOUS CONTEXT (read-only, do not include in output):
{context_block}

### CORRECT THE FOLLOWING (output only these entries):
{main_block}"""
        else:
            user_content = '\n'.join(main_entries)
        
        response = client.chat.completions.create(
            model=deployment_name,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content},
            ],
            temperature=0.0,  # Maximum determinism for consistent corrections
        )
        chunk_content = response.choices[0].message.content
        if chunk_content:
            cleaned_chunks.append(chunk_content)
        else:
            # If API returns None, keep original content
            cleaned_chunks.append('\n'.join(main_entries))
    
    return '\n\n'.join(cleaned_chunks)


def main():
    if len(sys.argv) != 2:
        print("Usage: python clean_transcript.py <input_file.srt>")
        sys.exit(1)
    
    input_path = Path(sys.argv[1])
    
    if not input_path.exists():
        print(f"Error: File '{input_path}' not found.")
        sys.exit(1)
    
    # Build output filename: [original_filename]_cleaned.srt
    output_path = input_path.with_stem(f"{input_path.stem}_cleaned")
    
    print(f"Loading configuration...")
    config = load_config()
    
    print(f"Reading '{input_path}'...")
    content = input_path.read_text(encoding="utf-8")
    
    print("Loading JSON context...")
    json_context = load_json_context()
    
    print(f"Sending to Azure OpenAI ({config['deployment_name']})...")
    client = create_client(config)
    cleaned_content = clean_transcript(client, config["deployment_name"], content, json_context)
    
    print(f"Writing cleaned transcript to '{output_path}'...")
    output_path.write_text(cleaned_content, encoding="utf-8")
    
    print("Done!")


if __name__ == "__main__":
    main()
